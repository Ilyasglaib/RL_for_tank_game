{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f873cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from envs import *\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pydirectinput\n",
    "import pygame\n",
    "from pygame.locals import *\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from agents import DQN_agent\n",
    "from agents.DQN_agent import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90fed7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_key_press(key):\n",
    "    pygame.event.post(pygame.event.Event(KEYDOWN, {'key': key}))\n",
    "\n",
    "def perform_action(action):\n",
    "    if action==0:\n",
    "        simulate_key_press(K_UP)\n",
    "    if action==1:\n",
    "        simulate_key_press(K_RIGHT)\n",
    "    if action==2:\n",
    "        simulate_key_press(K_DOWN)\n",
    "    if action==3:\n",
    "        simulate_key_press(K_LEFT)\n",
    "    if action==5:\n",
    "        simulate_key_press(K_SPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fc103a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialisation agent\n",
    "input_shape = (12, 22, 22)  # pour 4 images RGB 22x22\n",
    "num_actions = 6\n",
    "agent = DQNAgent(input_shape=input_shape, num_actions=num_actions)\n",
    "agent.model.load_state_dict(torch.load(\"C:/Users/DELL/Documents/Reinfrocement learning project/notebooks/checkpoints/model_ep2000.pth\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c047591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### environnement reset successfully ####\n",
      "[EVAL] Total reward : 4.980000000000056\n",
      "[EVAL] Final kill streak : 9\n"
     ]
    }
   ],
   "source": [
    "#Evaluation mode i.e without exploration or training\n",
    "\n",
    "agent.model.eval()  # Put the network on evaluation mode (no dropout, batchnorm, etc.)\n",
    "\n",
    "env = TankEnv()\n",
    "env.reset()\n",
    "frame_stack = deque(maxlen=4)\n",
    "\n",
    "# Set up the display\n",
    "screen_size = (env.max_x * 20, env.max_y * 20)  # Scale up the game screen\n",
    "screen = pygame.display.set_mode(screen_size)\n",
    "clock = pygame.time.Clock()\n",
    "\n",
    "current_frame=env.render() #The state now is the frame !\n",
    "\n",
    "for _ in range(4):\n",
    "    frame_stack.append(current_frame)\n",
    "frame_state = np.concatenate(list(frame_stack), axis=2)\n",
    "\n",
    "done=False\n",
    "total_reward=0\n",
    "\n",
    "while not done:\n",
    "    state_tensor = torch.tensor(frame_state, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        q_values = agent.model(state_tensor)\n",
    "        action = torch.argmax(q_values).item()\n",
    "        \n",
    "    #perform action\n",
    "    perform_action(action)\n",
    "\n",
    "    # Get the reward\n",
    "    next_state, reward,kill_streak, done,_ = env.step(action)\n",
    "\n",
    "    next_frame = env.render()\n",
    "    frame_stack.append(next_frame)\n",
    "    next_frame_state = np.concatenate(list(frame_stack), axis=2)\n",
    "\n",
    "    #render the game\n",
    "    frame=next_frame.copy()\n",
    "    frame = np.repeat(np.repeat(frame, 18, axis=0), 18, axis=1)  # Scale up the frame for visibility\n",
    "    surface = pygame.surfarray.make_surface(frame)\n",
    "    screen.blit(surface, (0, 0))\n",
    "    pygame.display.flip()\n",
    "\n",
    "    # Cap the frame rate\n",
    "    clock.tick(9)\n",
    "    \n",
    "    frame_state=next_frame_state\n",
    "    total_reward += reward\n",
    "\n",
    "print(f\"[EVAL] Total reward : {total_reward}\")\n",
    "print(f\"[EVAL] Final kill streak : {kill_streak}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
